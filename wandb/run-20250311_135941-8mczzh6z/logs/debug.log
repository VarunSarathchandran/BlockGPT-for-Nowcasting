2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_setup.py:_flush():68] Current SDK version is 0.19.1
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_setup.py:_flush():68] Configure stats pid to 2434055
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_setup.py:_flush():68] Loading settings from /home/cmeo/.config/wandb/settings
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_setup.py:_flush():68] Loading settings from /gpfs/home1/cmeo/Varun/ivideogpt/wandb/settings
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:_log_setup():528] Logging user logs to /gpfs/home1/cmeo/Varun/ivideogpt/wandb/run-20250311_135941-8mczzh6z/logs/debug.log
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:_log_setup():529] Logging internal logs to /gpfs/home1/cmeo/Varun/ivideogpt/wandb/run-20250311_135941-8mczzh6z/logs/debug-internal.log
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:init():644] calling init triggers
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:init():650] wandb.init called with sweep_config: {}
config: {}
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:init():680] starting backend
2025-03-11 13:59:41,048 INFO    MainThread:2434055 [wandb_init.py:init():684] sending inform_init request
2025-03-11 13:59:41,055 INFO    MainThread:2434055 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-03-11 13:59:41,055 INFO    MainThread:2434055 [wandb_init.py:init():697] backend started and connected
2025-03-11 13:59:41,058 INFO    MainThread:2434055 [wandb_init.py:init():790] updated telemetry
2025-03-11 13:59:41,059 INFO    MainThread:2434055 [wandb_init.py:init():822] communicating run to backend with 90.0 second timeout
2025-03-11 13:59:41,462 INFO    MainThread:2434055 [wandb_init.py:init():874] starting run threads in backend
2025-03-11 13:59:41,834 INFO    MainThread:2434055 [wandb_run.py:_console_start():2374] atexit reg
2025-03-11 13:59:41,834 INFO    MainThread:2434055 [wandb_run.py:_redirect():2224] redirect: wrap_raw
2025-03-11 13:59:41,834 INFO    MainThread:2434055 [wandb_run.py:_redirect():2289] Wrapping output streams.
2025-03-11 13:59:41,834 INFO    MainThread:2434055 [wandb_run.py:_redirect():2314] Redirects installed.
2025-03-11 13:59:41,840 INFO    MainThread:2434055 [wandb_init.py:init():916] run started, returning control to user process
2025-03-11 13:59:41,842 INFO    MainThread:2434055 [wandb_run.py:_config_callback():1279] config_cb None None {'config_name': 'configs/llama/config_w_vq_400M_1024.json', 'llama_attn_drop': 0.1, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'learning_rate': 1e-05, 'weight_decay': 0.01, 'num_train_epochs': 5, 'max_train_steps': 200000, 'dataset_name': 'knmi', 'gradient_accumulation_steps': 1, 'lr_scheduler_type': 'cosine', 'num_warmup_steps': 5000, 'output_dir': '/projects/0/prjs0951/Varun/log_trm/2025-03-11-13:59:14-knmi_trial', 'seed': 0, 'vqgan_type': 'vqgan', 'pretrained_model_name_or_path': '/projects/0/prjs0951/Varun/Checkpoints/vqgan_knmi_7M_1024_ckpt-177500.pt', 'n_tokens_per_frame': 64, 'encoder_config': 'configs/config_vqgan.json', 'pretrained_transformer_path': None, 'load_internal_llm': False, 'trust_remote_code': False, 'checkpointing_steps': 10000, 'resume_from_checkpoint': None, 'with_tracking': True, 'report_to': 'wandb', 'mixed_precision': None, 'exp_name': 'knmi_trial', 'lora': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.0, 'gradient_checkpointing': False, 'max_grad_norm': None, 'reward_prediction': False, 'start_completed_steps': None, 'action_recon': None, 'predictor_name': 'nanoGPT', 'segment_length': 9, 'context_length': 3, 'video_stepsize': 1, 'dataset_path': '/data2/frame_datasets', 'dataset_size': None, 'sthsth_root_path': '/data/something-something-v2/20bn-something-something-v2-frames-64', 'resolution': 128, 'dataloader_num_workers': 4, 'strong_aug': False, 'no_aug': False, 'oxe_data_mixes_type': 'select', 'log_steps': 100, 'validation_steps': 2000, 'skip_first_val': False, 'latest_checkpoint_only': False, 'special_token': True, 'action_conditioned': False, 'action_dim': 4, 'embed_no_wd': True, 'goal_conditioned': False, 'max_eval_iters': 100, 'use_eval_dataset': True, 'i3d_path': 'pretrained_models/i3d/i3d_torchscript.pt', 'use_frame_metrics': False, 'use_fvd': False, 'eval_generate_times': 1, 'max_generate_batchsize': None, 'max_decode_batchsize': None, 'eval_only': False, 'log_gif_interval': 10, 'debug': False, 'include_sos': True, 'model_type': 'llama'}
