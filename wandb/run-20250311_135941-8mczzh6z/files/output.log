03/11/2025 13:59:41 - INFO - __main__ - ***** Running training *****
03/11/2025 13:59:41 - INFO - __main__ -   Num examples = 17750
03/11/2025 13:59:41 - INFO - __main__ -   Num Epochs = 5
03/11/2025 13:59:41 - INFO - __main__ -   Instantaneous batch size per device = 4
03/11/2025 13:59:41 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
03/11/2025 13:59:41 - INFO - __main__ -   Gradient Accumulation steps = 1
03/11/2025 13:59:41 - INFO - __main__ -   Total optimization steps = 200000
  0%|          | 1/200000 [00:01<110:06:14,  1.98s/it, batch_time=1.98]
model is:  DistributedDataParallel(
  (module): GPT(
    (transformer): ModuleDict(
      (wte): Embedding(1025, 1024)
      (wpe): Embedding(585, 1024)
      (drop): Dropout(p=0.0, inplace=False)
      (h): ModuleList(
        (0-31): 32 x Block(
          (ln_1): LayerNorm()
          (attn): CausalSelfAttention(
            (c_attn): Linear(in_features=1024, out_features=3072, bias=False)
            (c_proj): Linear(in_features=1024, out_features=1024, bias=False)
            (attn_dropout): Dropout(p=0.0, inplace=False)
            (resid_dropout): Dropout(p=0.0, inplace=False)
          )
          (ln_2): LayerNorm()
          (mlp): MLP(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=False)
            (gelu): GELU(approximate='none')
            (c_proj): Linear(in_features=4096, out_features=1024, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (ln_f): LayerNorm()
    )
    (lm_head): Linear(in_features=1024, out_features=1025, bias=False)
  )
)
Number of parameters in the model: 404368384
h shape torch.Size([36, 128, 8, 8])
validation:  10%|â–ˆ         | 10/100 [00:05<00:26,  3.36it/s]
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1019, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1022, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
gen kwargs:  {'do_sample': True, 'temperature': 1.0, 'top_k': 100, 'max_new_tokens': 390}
repeat iters 1
iter number 0
gen input shape is torch.Size([4, 195])
generated tokens shape in each generate iter is:  torch.Size([4, 585])
results shape is  torch.Size([4, 585])
gen input shape is:  torch.Size([4, 195])
generated tokens shape is:  torch.Size([4, 585])
largest token in generated tokens  tensor(1024, device='cuda:0')
indices shape torch.Size([4, 584])
future length 6
largest index inside detokenize is  tensor(1023, device='cuda:0')
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
h shape torch.Size([36, 128, 8, 8])
